{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit card fraud detection using geographic data with PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession for PySpark \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import tools for data preprocessing\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Import ML libraries for classification\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "# Import tools for classification metric analysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"CreditCardFraudDetection\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://lena-master:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>CreditCardFraudDetection</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2ef2f6d790>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check session creation was successful\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Datasets available in directory:</i> \n",
    "<br>'hdfs://lena/user/blive001/fraudTest.csv', and \n",
    "<br>'hdfs://lena/user/blive001/fraudTrain.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "test_data = spark.read.format(\"csv\").option(\"inferSchema\",\"True\").option(\"header\",\"true\").load('hdfs://lena/user/blive001/fraudTest.csv')\n",
    "train_data = spark.read.format(\"csv\").option(\"inferSchema\",\"True\").option(\"header\",\"true\").load('hdfs://lena/user/blive001/fraudTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of test dataset: <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "Data type of train dataset: <class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Confirm datasets were loaded and check datatype\n",
    "print('Data type of test dataset:', type(test_data))\n",
    "print('Data type of train dataset:', type(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- trans_date_trans_time: string (nullable = true)\n",
      " |-- cc_num: long (nullable = true)\n",
      " |-- merchant: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- amt: double (nullable = true)\n",
      " |-- first: string (nullable = true)\n",
      " |-- last: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- street: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zip: integer (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- city_pop: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- trans_num: string (nullable = true)\n",
      " |-- unix_time: integer (nullable = true)\n",
      " |-- merch_lat: double (nullable = true)\n",
      " |-- merch_long: double (nullable = true)\n",
      " |-- is_fraud: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, _c0: string, trans_date_trans_time: string, cc_num: string, merchant: string, category: string, amt: string, first: string, last: string, gender: string, street: string, city: string, state: string, zip: string, lat: string, long: string, city_pop: string, job: string, dob: string, trans_num: string, unix_time: string, merch_lat: string, merch_long: string, is_fraud: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check basic meta data of test data\n",
    "test_data.printSchema()\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- trans_date_trans_time: string (nullable = true)\n",
      " |-- cc_num: long (nullable = true)\n",
      " |-- merchant: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- amt: double (nullable = true)\n",
      " |-- first: string (nullable = true)\n",
      " |-- last: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- street: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zip: integer (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- city_pop: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- trans_num: string (nullable = true)\n",
      " |-- unix_time: integer (nullable = true)\n",
      " |-- merch_lat: double (nullable = true)\n",
      " |-- merch_long: double (nullable = true)\n",
      " |-- is_fraud: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, _c0: string, trans_date_trans_time: string, cc_num: string, merchant: string, category: string, amt: string, first: string, last: string, gender: string, street: string, city: string, state: string, zip: string, lat: string, long: string, city_pop: string, job: string, dob: string, trans_num: string, unix_time: string, merch_lat: string, merch_long: string, is_fraud: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check basic meta data of train data\n",
    "train_data.printSchema()\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " _c0                   | 0                    \n",
      " trans_date_trans_time | 2019-01-01 00:00:18  \n",
      " cc_num                | 2703186189652095     \n",
      " merchant              | fraud_Rippin, Kub... \n",
      " category              | misc_net             \n",
      " amt                   | 4.97                 \n",
      " first                 | Jennifer             \n",
      " last                  | Banks                \n",
      " gender                | F                    \n",
      " street                | 561 Perry Cove       \n",
      " city                  | Moravian Falls       \n",
      " state                 | NC                   \n",
      " zip                   | 28654                \n",
      " lat                   | 36.0788              \n",
      " long                  | -81.1781             \n",
      " city_pop              | 3495                 \n",
      " job                   | Psychologist, cou... \n",
      " dob                   | 1988-03-09           \n",
      " trans_num             | 0b242abb623afc578... \n",
      " unix_time             | 1325376018           \n",
      " merch_lat             | 36.011293            \n",
      " merch_long            | -82.048315           \n",
      " is_fraud              | 0                    \n",
      "-RECORD 1-------------------------------------\n",
      " _c0                   | 1                    \n",
      " trans_date_trans_time | 2019-01-01 00:00:44  \n",
      " cc_num                | 630423337322         \n",
      " merchant              | fraud_Heller, Gut... \n",
      " category              | grocery_pos          \n",
      " amt                   | 107.23               \n",
      " first                 | Stephanie            \n",
      " last                  | Gill                 \n",
      " gender                | F                    \n",
      " street                | 43039 Riley Green... \n",
      " city                  | Orient               \n",
      " state                 | WA                   \n",
      " zip                   | 99160                \n",
      " lat                   | 48.8878              \n",
      " long                  | -118.2105            \n",
      " city_pop              | 149                  \n",
      " job                   | Special education... \n",
      " dob                   | 1978-06-21           \n",
      " trans_num             | 1f76529f857473494... \n",
      " unix_time             | 1325376044           \n",
      " merch_lat             | 49.159046999999994   \n",
      " merch_long            | -118.186462          \n",
      " is_fraud              | 0                    \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View example of data to see what format string data is in etc. \n",
    "train_data.show(vertical=True, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of values in train_data: 1296675\n",
      "Number of values in test_data:  555719\n"
     ]
    }
   ],
   "source": [
    "# NUmber of entries in test and train data\n",
    "print('Number of values in train_data:', train_data.count())\n",
    "print('Number of values in test_data: ', test_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge train and test data sets for pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data needs to be in train/test datasets for classification but before that step, the data needs to be pre-processed. For the next step, I will combine the two sets into one new dataset for pre-processing. It will be resplit into a train and test set at a later point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate test and training data together\n",
    "all_data = train_data.union(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of values in all_data: 1852394\n"
     ]
    }
   ],
   "source": [
    "# Confirm concatination was successful and check number of samples in full set\n",
    "print('Number of values in all_data:', all_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploritory Data Analysis and Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now time to take a closer look at the data to find information needed for the later classification phase. I am combining the EDA with the pre-processing of the data as I will be working with and manipulating the data as points of interest arrise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " 'trans_date_trans_time',\n",
       " 'cc_num',\n",
       " 'merchant',\n",
       " 'category',\n",
       " 'amt',\n",
       " 'first',\n",
       " 'last',\n",
       " 'gender',\n",
       " 'street',\n",
       " 'city',\n",
       " 'state',\n",
       " 'zip',\n",
       " 'lat',\n",
       " 'long',\n",
       " 'city_pop',\n",
       " 'job',\n",
       " 'dob',\n",
       " 'trans_num',\n",
       " 'unix_time',\n",
       " 'merch_lat',\n",
       " 'merch_long',\n",
       " 'is_fraud']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View names of all columns in DataFrame\n",
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values of 'cc_num': 999\n",
      "Number of unique values of 'merchant': 693\n",
      "Number of unique values of 'category': 14\n",
      "Number of unique values of 'city': 906\n",
      "Number of unique values of 'state': 51\n",
      "Number of unique values of 'merch_lat': 1754157\n",
      "Number of unique values of 'merch_long': 1809753\n"
     ]
    }
   ],
   "source": [
    "# Check number of unique values in main categorical features of interest\n",
    "temp_cats = ['cc_num', 'merchant', 'category', 'city', 'state', 'merch_lat', 'merch_long']\n",
    "for col in temp_cats:\n",
    "    print('Number of unique values of ' + '\\'' + str(col) + '\\'' + ':', all_data.select(col).distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suspect the 'merchant' may be a key factor in determining if the data is frand or not. This is based on a logically assumption that fraudsters are likely to work in a certain area and potentially uses merchants who may cut corners or follow the rules less strictly. As such, I want to investigate the 'merchant' column.\n",
    "\n",
    "As the total number of data points is 1852394 and the number of unique merchants is 693, I would like to get an idea of if this in rougly equally sread or stacked in several main merchants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            merchant|count|\n",
      "+--------------------+-----+\n",
      "| fraud_Abbott-Rogahn| 2647|\n",
      "|fraud_Abbott-Steuber| 2529|\n",
      "|fraud_Abernathy a...| 2513|\n",
      "|   fraud_Abshire PLC| 2733|\n",
      "|fraud_Adams, Kova...| 1354|\n",
      "| fraud_Adams-Barrows| 2535|\n",
      "|fraud_Altenwerth,...| 2755|\n",
      "|fraud_Altenwerth-...| 3594|\n",
      "| fraud_Ankunding LLC| 2782|\n",
      "|fraud_Ankunding-C...| 1155|\n",
      "|fraud_Armstrong, ...| 2649|\n",
      "|      fraud_Auer LLC| 2674|\n",
      "| fraud_Auer-Mosciski| 3487|\n",
      "|     fraud_Auer-West| 2793|\n",
      "|fraud_Bahringer G...| 2435|\n",
      "|fraud_Bahringer, ...| 3552|\n",
      "|fraud_Bahringer, ...| 2569|\n",
      "|fraud_Bahringer, ...| 3313|\n",
      "|fraud_Bahringer-L...| 1240|\n",
      "|fraud_Bahringer-S...| 2558|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a total amount of times each merchant appears\n",
    "all_data.groupBy('merchant').count().sort('merchant').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(count)|\n",
      "+-----------------+\n",
      "|2673.007215007215|\n",
      "+-----------------+\n",
      "\n",
      "+-----------------+\n",
      "|    stddev(count)|\n",
      "+-----------------+\n",
      "|819.2381408667195|\n",
      "+-----------------+\n",
      "\n",
      "+----------+\n",
      "|max(count)|\n",
      "+----------+\n",
      "|      6262|\n",
      "+----------+\n",
      "\n",
      "+----------+\n",
      "|min(count)|\n",
      "+----------+\n",
      "|      1090|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show summary stastics of 'merchant' columns (mean, std, max, min)\n",
    "all_data.groupBy('merchant').count().agg({'count': 'mean'}).show()\n",
    "all_data.groupBy('merchant').count().agg({'count': 'stddev'}).show()\n",
    "all_data.groupBy('merchant').count().agg({'count': 'max'}).show()\n",
    "all_data.groupBy('merchant').count().agg({'count': 'min'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having investigated the 'marchant' column, the results appear fine and the be reasonably well distibuted. There do appear to be some extreme outliers, but this may be the kind which indicate fraud or could simply be a merchant in a big city. I will now move on to checking there are no NaNs in the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values for each column:\n",
      "-RECORD 0--------------------\n",
      " _c0                   | 0   \n",
      " trans_date_trans_time | 0   \n",
      " cc_num                | 0   \n",
      " merchant              | 0   \n",
      " category              | 0   \n",
      " amt                   | 0   \n",
      " first                 | 0   \n",
      " last                  | 0   \n",
      " gender                | 0   \n",
      " street                | 0   \n",
      " city                  | 0   \n",
      " state                 | 0   \n",
      " zip                   | 0   \n",
      " lat                   | 0   \n",
      " long                  | 0   \n",
      " city_pop              | 0   \n",
      " job                   | 0   \n",
      " dob                   | 0   \n",
      " trans_num             | 0   \n",
      " unix_time             | 0   \n",
      " merch_lat             | 0   \n",
      " merch_long            | 0   \n",
      " is_fraud              | 0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in dataframe\n",
    "from pyspark.sql.functions import *\n",
    "print(\"Number of NaN values for each column:\")\n",
    "all_data.select([count(when((col(i)=='') | col(i).isNull() | isnan(i), i)).alias(i) for i in all_data.columns]).show(vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset appears to be a clean daatset, free on NaNs. Next I will move on to checking the class balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number on instances of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for class 1: 9651\n",
      "Number of samples for class 1: 1842743\n"
     ]
    }
   ],
   "source": [
    "# Check count of each class\n",
    "print('Number of samples for class 1:', all_data.select().where(all_data[\"is_fraud\"]==1).count())\n",
    "print('Number of samples for class 1:', all_data.select().where(all_data[\"is_fraud\"]==0).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the dataset is heavily imbalanced with around 99.5% class 0. This will likley cause issues in training where the classifier is able to simply guess 'not fraud' every time and achieve 99.5% accuracy. To avoid this issue, I will use oversampling of the fraud class (1) to increase instances of it. I am a little concerned with how far the dat will have to be stretched via oversampling. However, given the dataset is all synthetic data to start with, it may not be too diffifult for it to stretch the 1 class. \n",
    "\n",
    "Note: An alternative method would be undersampling, however this would involve throwing away around 99% of our data, which I do not think would benefit training. While it is possible some hybrid approach would work best in real life, as this is completely synthetic data, I will use oversampling as my main method to aviod losing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rebalance the dataset with over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of non-fraud to fraud values in dataset: 190:1\n"
     ]
    }
   ],
   "source": [
    "# Find ratio of class 0 to class 1\n",
    "non_fraud = all_data.filter(col(\"is_fraud\") == 0)\n",
    "fraud = all_data.filter(col(\"is_fraud\") == 1)\n",
    "class_ratio = int(non_fraud.count()/fraud.count())\n",
    "print(\"Ratio of non-fraud to fraud values in dataset: \" + str(class_ratio) + \":1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample the fraud (1) class to approximately equal that of the non-fraud class (0)\n",
    "\n",
    "### Note: based on code of Jun Wan in article \"Oversampling and Undersampling with PySpark\"[7]\n",
    "length = range(class_ratio)\n",
    "# Create duplicates of non-fraud class\n",
    "oversampled_data = fraud.withColumn(\"dummy\", explode(array([lit(x) for x in length]))).drop('dummy')\n",
    "# Create new df with a higher number of non-fraud samples\n",
    "equal_data = non_fraud.unionAll(oversampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for class 1: 1833690\n",
      "Number of samples for class 1: 1842743\n"
     ]
    }
   ],
   "source": [
    "# Confirm the oversampling was successful\n",
    "print('Number of samples for class 1:', equal_data.select().where(equal_data[\"is_fraud\"]==1).count())\n",
    "print('Number of samples for class 1:', equal_data.select().where(equal_data[\"is_fraud\"]==0).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes have now been rebalanced at apporximately a 50:50 ratio. I can now move on to transforming the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create 'day', 'week', and 'year' variables from 'trans_date_trans_time' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible fraud is tied to certain timings, public events etc. The 'trans_date_trans_time' column appears as a more linear way of looking at time as opposed to a periodical approach, which may be more relevant for pattern recognition. Therefore, I will be transforming the current 'trans_date_trans_time' column (which is a String) to something which is more usable by creating 'day' (day of week), 'week' (week of year), and 'year' columns thorugh an intermediary 'timestamp' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying 'trans_date_trans_time' to a timestamp \n",
    "mod_df = equal_data.withColumn(\"timestamp\", to_timestamp(col(\"trans_date_trans_time\"), 'yyyy-MM-dd HH:mm:ss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'day', 'week', 'year' columns from 'timestamp'\n",
    "mod_df=mod_df.withColumn('day',dayofweek('timestamp')).withColumn('week',weekofyear(\n",
    "    'timestamp')).withColumn('year',year('timestamp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create age variable from 'dob'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date of birth may be difficult for the classifier to interpret so an age variable will be created to replace it with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'age' column from 'dob'\n",
    "mod_df=mod_df.withColumn('age', round(datediff(current_date(),col(\"dob\"))/365.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " _c0                   | 0                    \n",
      " trans_date_trans_time | 2019-01-01 00:00:18  \n",
      " cc_num                | 2703186189652095     \n",
      " merchant              | fraud_Rippin, Kub... \n",
      " category              | misc_net             \n",
      " amt                   | 4.97                 \n",
      " first                 | Jennifer             \n",
      " last                  | Banks                \n",
      " gender                | F                    \n",
      " street                | 561 Perry Cove       \n",
      " city                  | Moravian Falls       \n",
      " state                 | NC                   \n",
      " zip                   | 28654                \n",
      " lat                   | 36.0788              \n",
      " long                  | -81.1781             \n",
      " city_pop              | 3495                 \n",
      " job                   | Psychologist, cou... \n",
      " dob                   | 1988-03-09           \n",
      " trans_num             | 0b242abb623afc578... \n",
      " unix_time             | 1325376018           \n",
      " merch_lat             | 36.011293            \n",
      " merch_long            | -82.048315           \n",
      " is_fraud              | 0                    \n",
      " timestamp             | 2019-01-01 00:00:18  \n",
      " day                   | 3                    \n",
      " week                  | 1                    \n",
      " year                  | 2019                 \n",
      " age                   | 34.0                 \n",
      "-RECORD 1-------------------------------------\n",
      " _c0                   | 1                    \n",
      " trans_date_trans_time | 2019-01-01 00:00:44  \n",
      " cc_num                | 630423337322         \n",
      " merchant              | fraud_Heller, Gut... \n",
      " category              | grocery_pos          \n",
      " amt                   | 107.23               \n",
      " first                 | Stephanie            \n",
      " last                  | Gill                 \n",
      " gender                | F                    \n",
      " street                | 43039 Riley Green... \n",
      " city                  | Orient               \n",
      " state                 | WA                   \n",
      " zip                   | 99160                \n",
      " lat                   | 48.8878              \n",
      " long                  | -118.2105            \n",
      " city_pop              | 149                  \n",
      " job                   | Special education... \n",
      " dob                   | 1978-06-21           \n",
      " trans_num             | 1f76529f857473494... \n",
      " unix_time             | 1325376044           \n",
      " merch_lat             | 49.159046999999994   \n",
      " merch_long            | -118.186462          \n",
      " is_fraud              | 0                    \n",
      " timestamp             | 2019-01-01 00:00:44  \n",
      " day                   | 3                    \n",
      " week                  | 1                    \n",
      " year                  | 2019                 \n",
      " age                   | 44.0                 \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confirm the new columns have been made\n",
    "mod_df.show(vertical=True, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- trans_date_trans_time: string (nullable = true)\n",
      " |-- cc_num: long (nullable = true)\n",
      " |-- merchant: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- amt: double (nullable = true)\n",
      " |-- first: string (nullable = true)\n",
      " |-- last: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- street: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- zip: integer (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- city_pop: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- dob: string (nullable = true)\n",
      " |-- trans_num: string (nullable = true)\n",
      " |-- unix_time: integer (nullable = true)\n",
      " |-- merch_lat: double (nullable = true)\n",
      " |-- merch_long: double (nullable = true)\n",
      " |-- is_fraud: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check type of new columns\n",
    "mod_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop columns deemed unlikely to be useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now drop columns which appear unlikely to add substantial benefit but may confuse the classifier during training. The index column, '_c0', can definitely be dropped as well as columns related to customer name and address (the latitude and longitude have been kept so city is not needed and may cause confusion). The temporary 'timestamp' column can also be dropped as well as 'dob', which is now not needed, and 'trans_num'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns with no expected benefit to classification\n",
    "to_drop = ['_c0', 'trans_date_trans_time', 'first', 'last', 'street', 'city', 'zip', 'trans_num', 'timestamp', 'dob']\n",
    "mod_df_small = mod_df.drop(*to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cc_num: long (nullable = true)\n",
      " |-- merchant: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- amt: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- city_pop: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- unix_time: integer (nullable = true)\n",
      " |-- merch_lat: double (nullable = true)\n",
      " |-- merch_long: double (nullable = true)\n",
      " |-- is_fraud: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check drop was successful\n",
    "mod_df_small.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One hot encoding of categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now one-hot-encode the categorical variabels which I plan on using in the final model. They will be one-hot-encoded to ensure the classifier only views them as binary variables during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of variables to be onehotencoded\n",
    "cols_categorical = [\"category\", \"gender\", \"job\", \"state\", \"merchant\"]\n",
    " \n",
    "# Create stringIndexer for indexes\n",
    "stringIndexer = StringIndexer(inputCols=cols_categorical, outputCols=[x + \"_index\" for x in cols_categorical])\n",
    "# Store stringIndexer in temp df\n",
    "temp_df = stringIndexer.fit(mod_df_small).transform(mod_df_small)\n",
    "# Create encoder for onehotencoded categories\n",
    "encoder = OneHotEncoder(inputCols=stringIndexer.getOutputCols(), outputCols=[x + \"_OHE\" for x in cols_categorical])\n",
    "# Create new df with encoded variables added\n",
    "encoded_df = encoder.fit(temp_df).transform(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-----------------+---------+---------------+--------------+\n",
      "|   gender_OHE|gender_index|          job_OHE|job_index|   category_OHE|category_index|\n",
      "+-------------+------------+-----------------+---------+---------------+--------------+\n",
      "|(1,[0],[1.0])|         0.0|(496,[170],[1.0])|    170.0| (13,[4],[1.0])|           4.0|\n",
      "|(1,[0],[1.0])|         0.0|(496,[104],[1.0])|    104.0| (13,[0],[1.0])|           0.0|\n",
      "|    (1,[],[])|         1.0|(496,[371],[1.0])|    371.0| (13,[7],[1.0])|           7.0|\n",
      "|    (1,[],[])|         1.0|(496,[204],[1.0])|    204.0| (13,[3],[1.0])|           3.0|\n",
      "|    (1,[],[])|         1.0|(496,[291],[1.0])|    291.0| (13,[9],[1.0])|           9.0|\n",
      "|(1,[0],[1.0])|         0.0|(496,[201],[1.0])|    201.0| (13,[3],[1.0])|           3.0|\n",
      "|(1,[0],[1.0])|         0.0|(496,[154],[1.0])|    154.0|(13,[12],[1.0])|          12.0|\n",
      "|    (1,[],[])|         1.0|(496,[330],[1.0])|    330.0| (13,[3],[1.0])|           3.0|\n",
      "|(1,[0],[1.0])|         0.0|(496,[227],[1.0])|    227.0| (13,[9],[1.0])|           9.0|\n",
      "|(1,[0],[1.0])|         0.0|(496,[401],[1.0])|    401.0| (13,[0],[1.0])|           0.0|\n",
      "|    (1,[],[])|         1.0| (496,[14],[1.0])|     14.0| (13,[0],[1.0])|           0.0|\n",
      "|(1,[0],[1.0])|         0.0| (496,[10],[1.0])|     10.0| (13,[1],[1.0])|           1.0|\n",
      "|    (1,[],[])|         1.0|(496,[266],[1.0])|    266.0| (13,[0],[1.0])|           0.0|\n",
      "|    (1,[],[])|         1.0| (496,[87],[1.0])|     87.0| (13,[0],[1.0])|           0.0|\n",
      "|    (1,[],[])|         1.0|  (496,[0],[1.0])|      0.0| (13,[2],[1.0])|           2.0|\n",
      "|    (1,[],[])|         1.0|(496,[169],[1.0])|    169.0| (13,[1],[1.0])|           1.0|\n",
      "|(1,[0],[1.0])|         0.0|(496,[166],[1.0])|    166.0| (13,[4],[1.0])|           4.0|\n",
      "|    (1,[],[])|         1.0| (496,[34],[1.0])|     34.0| (13,[2],[1.0])|           2.0|\n",
      "|    (1,[],[])|         1.0|(496,[343],[1.0])|    343.0|(13,[10],[1.0])|          10.0|\n",
      "|    (1,[],[])|         1.0|(496,[284],[1.0])|    284.0| (13,[0],[1.0])|           0.0|\n",
      "+-------------+------------+-----------------+---------+---------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View some of the orginal and _OHE columns to check the outcome was as expected\n",
    "encoded_df.select('gender_OHE', 'gender_index','job_OHE','job_index','category_OHE', 'category_index').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cc_num: long (nullable = true)\n",
      " |-- merchant: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- amt: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- city_pop: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- unix_time: integer (nullable = true)\n",
      " |-- merch_lat: double (nullable = true)\n",
      " |-- merch_long: double (nullable = true)\n",
      " |-- is_fraud: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- merchant_index: double (nullable = false)\n",
      " |-- category_index: double (nullable = false)\n",
      " |-- gender_index: double (nullable = false)\n",
      " |-- state_index: double (nullable = false)\n",
      " |-- job_index: double (nullable = false)\n",
      " |-- category_OHE: vector (nullable = true)\n",
      " |-- state_OHE: vector (nullable = true)\n",
      " |-- merchant_OHE: vector (nullable = true)\n",
      " |-- gender_OHE: vector (nullable = true)\n",
      " |-- job_OHE: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check columns and dtypes are now in dataframe\n",
    "encoded_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping now irrelevant columns with superseded variations\n",
    "to_drop = ['merchant_index', 'state_index', 'job_index', 'gender_index', 'category_index',\n",
    "          'merchant', 'state', 'job', 'gender', 'category']\n",
    "clean_encoded_df = encoded_df.drop(*to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cc_num: long (nullable = true)\n",
      " |-- amt: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- city_pop: integer (nullable = true)\n",
      " |-- unix_time: integer (nullable = true)\n",
      " |-- merch_lat: double (nullable = true)\n",
      " |-- merch_long: double (nullable = true)\n",
      " |-- is_fraud: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- category_OHE: vector (nullable = true)\n",
      " |-- state_OHE: vector (nullable = true)\n",
      " |-- merchant_OHE: vector (nullable = true)\n",
      " |-- gender_OHE: vector (nullable = true)\n",
      " |-- job_OHE: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check dropping was successful and what columns and dtypes are currently in dataframe\n",
    "clean_encoded_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data normalization with MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric variables will now be normalized to avoid the classifier from potentially over focusing on columns which have a higher range than other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of variables to be MinMaxScaled\n",
    "cols_numeric = [\"cc_num\", \"amt\", \"lat\", \"long\", \"city_pop\", \"unix_time\", \"merch_lat\", \"merch_long\", \n",
    "                \"day\", \"week\", \"year\", \"age\"]\n",
    "\n",
    "# Use VectorAssembler to create vector for each column\n",
    "assembler = [VectorAssembler(inputCols = [i], outputCol = i + \"_vec\") for i in cols_numeric]\n",
    "# Create MinMaxScaler for each column\n",
    "minmaxscaler = [MinMaxScaler(inputCol = i + \"_vec\", outputCol = i + \"_scaled\") for i in cols_numeric]\n",
    "# Create pipeline\n",
    "pipeline = Pipeline(stages = assembler + minmaxscaler)\n",
    "# Normalize data\n",
    "normalized_data = pipeline.fit(clean_encoded_df).transform(clean_encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cc_num: long (nullable = true)\n",
      " |-- amt: double (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- city_pop: integer (nullable = true)\n",
      " |-- unix_time: integer (nullable = true)\n",
      " |-- merch_lat: double (nullable = true)\n",
      " |-- merch_long: double (nullable = true)\n",
      " |-- is_fraud: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- category_OHE: vector (nullable = true)\n",
      " |-- state_OHE: vector (nullable = true)\n",
      " |-- merchant_OHE: vector (nullable = true)\n",
      " |-- gender_OHE: vector (nullable = true)\n",
      " |-- job_OHE: vector (nullable = true)\n",
      " |-- cc_num_vec: vector (nullable = true)\n",
      " |-- amt_vec: vector (nullable = true)\n",
      " |-- lat_vec: vector (nullable = true)\n",
      " |-- long_vec: vector (nullable = true)\n",
      " |-- city_pop_vec: vector (nullable = true)\n",
      " |-- unix_time_vec: vector (nullable = true)\n",
      " |-- merch_lat_vec: vector (nullable = true)\n",
      " |-- merch_long_vec: vector (nullable = true)\n",
      " |-- day_vec: vector (nullable = true)\n",
      " |-- week_vec: vector (nullable = true)\n",
      " |-- year_vec: vector (nullable = true)\n",
      " |-- age_vec: vector (nullable = true)\n",
      " |-- cc_num_scaled: vector (nullable = true)\n",
      " |-- amt_scaled: vector (nullable = true)\n",
      " |-- lat_scaled: vector (nullable = true)\n",
      " |-- long_scaled: vector (nullable = true)\n",
      " |-- city_pop_scaled: vector (nullable = true)\n",
      " |-- unix_time_scaled: vector (nullable = true)\n",
      " |-- merch_lat_scaled: vector (nullable = true)\n",
      " |-- merch_long_scaled: vector (nullable = true)\n",
      " |-- day_scaled: vector (nullable = true)\n",
      " |-- week_scaled: vector (nullable = true)\n",
      " |-- year_scaled: vector (nullable = true)\n",
      " |-- age_scaled: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check normalized columns were created as expected\n",
    "normalized_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop now obsolete columns \n",
    "normalized_data = normalized_data.drop('age_vec', 'year_vec', 'week_vec', 'day_vec', 'merch_long_vec', 'merch_lat_vec', \n",
    "                                       'unix_time_vec','city_pop_vec', 'long_vec', 'lat_vec', 'amt_vec', 'cc_num_vec', \n",
    "                                       'cc_num', 'amt', 'lat', 'long', 'city_pop', 'unix_time', 'merch_lat', 'merch_long',\n",
    "                                       'day', 'week', 'year', 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- is_fraud: integer (nullable = true)\n",
      " |-- category_OHE: vector (nullable = true)\n",
      " |-- state_OHE: vector (nullable = true)\n",
      " |-- merchant_OHE: vector (nullable = true)\n",
      " |-- gender_OHE: vector (nullable = true)\n",
      " |-- job_OHE: vector (nullable = true)\n",
      " |-- cc_num_scaled: vector (nullable = true)\n",
      " |-- amt_scaled: vector (nullable = true)\n",
      " |-- lat_scaled: vector (nullable = true)\n",
      " |-- long_scaled: vector (nullable = true)\n",
      " |-- city_pop_scaled: vector (nullable = true)\n",
      " |-- unix_time_scaled: vector (nullable = true)\n",
      " |-- merch_lat_scaled: vector (nullable = true)\n",
      " |-- merch_long_scaled: vector (nullable = true)\n",
      " |-- day_scaled: vector (nullable = true)\n",
      " |-- week_scaled: vector (nullable = true)\n",
      " |-- year_scaled: vector (nullable = true)\n",
      " |-- age_scaled: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View final dataset to ensure it is as expected\n",
    "normalized_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our final dataset with the dessired columns to work with for model training consisting of a label colum 'is_fraud' and normalized/one-hot-encoded columns:\n",
    "<br><i>is_fraud</i>\n",
    "<br><i>category_OHE</i> \n",
    "<br><i>state_OHE</i>\n",
    "<br><i>merchant_OHE</i> \n",
    "<br><i>gender_OHE</i> \n",
    "<br><i>job_OHE</i> \n",
    "<br><i>cc_num_scaled</i> \n",
    "<br><i>amt_scaled</i> \n",
    "<br><i>lat_scaled</i> \n",
    "<br><i>long_scaled</i> \n",
    "<br><i>city_pop_scaled</i> \n",
    "<br><i>unix_time_scaled</i> \n",
    "<br><i>merch_lat_scaled</i> \n",
    "<br><i>merch_long_scaled</i> \n",
    "<br><i>day_scaled</i> \n",
    "<br><i>week_scaled</i> \n",
    "<br><i>year_scaledr</i> \n",
    "<br><i>age_scaled</i> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can now be re-split into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of values in train_data: 2941039\n",
      "Number of values in test_data:  735394\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "train, test = normalized_data.randomSplit([0.8, 0.2])\n",
    "\n",
    "print('Number of values in train_data:', train.count())\n",
    "print('Number of values in test_data: ', test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine all feature columns into single feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step before classification in PySpark is to combine all feature data into a single vector. I will do this by creating a small function to create a list of input columns and run it through VectorAssembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to take all columns except class\n",
    "def drop_class_from_array(data, unwanted):\n",
    "    '''\n",
    "    A function which return a new array of all columns in the input array other than one specified to drop.\n",
    "    '''\n",
    "    return [col for col in data if col != unwanted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run drop_class_from_array to create list of input columns (all columns excpet class)\n",
    "inputCols = train.columns\n",
    "inputCols = drop_class_from_array(inputCols, 'is_fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['category_OHE',\n",
       " 'state_OHE',\n",
       " 'merchant_OHE',\n",
       " 'gender_OHE',\n",
       " 'job_OHE',\n",
       " 'cc_num_scaled',\n",
       " 'amt_scaled',\n",
       " 'lat_scaled',\n",
       " 'long_scaled',\n",
       " 'city_pop_scaled',\n",
       " 'unix_time_scaled',\n",
       " 'merch_lat_scaled',\n",
       " 'merch_long_scaled',\n",
       " 'day_scaled',\n",
       " 'week_scaled',\n",
       " 'year_scaled',\n",
       " 'age_scaled']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check result was successful from 'drop_class_from_array'\n",
    "inputCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VectorAssembler\n",
    "assembler = VectorAssembler(inputCols = inputCols, outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use assembler on train and test data\n",
    "train_assembled = assembler.transform(train)\n",
    "test_assembled = assembler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|            features|is_fraud|\n",
      "+--------------------+--------+\n",
      "|(1264,[13,909,125...|       0|\n",
      "|(1264,[13,984,125...|       0|\n",
      "+--------------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visually check results are as expected for train data\n",
    "train_assembled.select(['features', 'is_fraud']).show(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|            features|is_fraud|\n",
      "+--------------------+--------+\n",
      "|(1264,[13,782,125...|       0|\n",
      "|(1264,[13,810,125...|       0|\n",
      "+--------------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visually check results are as expected for test data\n",
    "test_assembled.select(['features', 'is_fraud']).show(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifcation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now at a point where it can be used for training for classification. \n",
    "\n",
    "I wil create a series of classifers to train and predict on to compare results to find the most appropriate for this dataset. The classifier to be tester are taken from Spark MLlib. The ones to be used are:\n",
    "<br><i>Naive Bayes classifier</i> \n",
    "<br><i>Logistic Regression classifier</i> \n",
    "<br><i>Decision Tree classifier</i> \n",
    "<br>and the ensemble:\n",
    "<br><i>RandomForest Classifier</i> \n",
    "\n",
    "As the main focus of the task is to detect CCF cases (while also not misclassifying too many non-CCF cases) the main metrics of interest will be accuracy and recall. \n",
    "\n",
    "For the sake of completeness, and as it may be relevant in certain situations, precision and ROC metrics will also be calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create accuracy evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up accuracy evaluators for accuracy, recall, precision, and ROC\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"is_fraud\", predictionCol=\"prediction\", \n",
    "                                              metricName=\"accuracy\") \n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"is_fraud\", predictionCol=\"prediction\", \n",
    "                                              metricName=\"recallByLabel\") \n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"is_fraud\", predictionCol=\"prediction\", \n",
    "                                              metricName=\"precisionByLabel\")\n",
    "ROC_evaluator = BinaryClassificationEvaluator(labelCol=\"is_fraud\", rawPredictionCol=\"prediction\", metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model to test will be a general industry standard in baseline<sup>[6]</sup>, the Naive Bayes model. I'm not expecting NB to perform extremely well on the data given it's assumption of data independence, but it will be a good first indicator to see how accurately the fraud cases can be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Naive Bayes Classifier\n",
    "NB = NaiveBayes(smoothing=1.0, modelType=\"multinomial\", featuresCol='features', labelCol='is_fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit data to the model\n",
    "NB_clf = NB.fit(train_assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to predict class\n",
    "predictions_df = NB_clf.transform(test_assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set:   0.7113166547456193\n",
      "Recall on test set:     0.7147962093029571\n",
      "Precision on test set:  0.7104900918213667\n",
      "ROC on test set:        0.7113112239245307\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy, recall, precision\n",
    "nb_accuracy = accuracy_evaluator.evaluate(predictions_df)\n",
    "print(\"Accuracy on test set:  \", nb_accuracy)\n",
    "nb_recall = recall_evaluator.evaluate(predictions_df)\n",
    "print(\"Recall on test set:    \", nb_recall)\n",
    "nb_precision = precision_evaluator.evaluate(predictions_df)\n",
    "print(\"Precision on test set: \", nb_precision)\n",
    "ROC = ROC_evaluator.evaluate(predictions_df)\n",
    "print(\"ROC on test set:       \", ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[263238 105032]\n",
      " [107264 259860]]\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix of results\n",
    "y_true = predictions_df.select(['is_fraud']).collect()\n",
    "y_pred = predictions_df.select(['prediction']).collect()\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71    368270\n",
      "           1       0.71      0.71      0.71    367124\n",
      "\n",
      "    accuracy                           0.71    735394\n",
      "   macro avg       0.71      0.71      0.71    735394\n",
      "weighted avg       0.71      0.71      0.71    735394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate pre-made classification report as a snaity check and to get weighted and f1-scores\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB has performed reasonably well on the dataset. It's achieved overall accuracy, precision, recall, and ROC all just over 71%. It has beaten our baseline of 50% accuracy and recall. It can be used as our standard baseline to beat moving forward.\n",
    "\n",
    "We will now move on to LogisticRegression for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LogisticRegression Classifier\n",
    "LR = LogisticRegression(featuresCol = \"features\", predictionCol=\"prediction\", labelCol='is_fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit data to the model\n",
    "LR_clf = LR.fit(train_assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to predict class\n",
    "predictions_LR = LR_clf.transform(test_assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set:   0.8485039485846764\n",
      "Recall on test set:     0.8906614025274385\n",
      "Precision on test set:  0.8220250208005453\n",
      "ROC on test set:        0.8483894881778773\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy, recall, precision, and ROC\n",
    "LR_accuracy = accuracy_evaluator.evaluate(predictions_LR)\n",
    "print(\"Accuracy on test set:  \", LR_accuracy)\n",
    "LR_recall = recall_evaluator.evaluate(predictions_LR)\n",
    "print(\"Recall on test set:    \", LR_recall)\n",
    "LR_precision = precision_evaluator.evaluate(predictions_LR)\n",
    "print(\"Precision on test set: \", LR_precision)\n",
    "ROC = ROC_evaluator.evaluate(predictions_LR)\n",
    "print(\"ROC on test set:       \", ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[328011  40267]\n",
      " [ 71017 295272]]\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix of results\n",
    "y_true = predictions_LR.select(['is_fraud']).collect()\n",
    "y_pred = predictions_LR.select(['prediction']).collect()\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85    368278\n",
      "           1       0.88      0.81      0.84    366289\n",
      "\n",
      "    accuracy                           0.85    734567\n",
      "   macro avg       0.85      0.85      0.85    734567\n",
      "weighted avg       0.85      0.85      0.85    734567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate pre-made classification report as a snaity check and to get weighted and f1-scores\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression has certainly performed better than the NB classifer. This isn't unexpected given the assumptions of NB. \n",
    "\n",
    "LogisticRegression has achieved a high accuracy of 85% and a very good recall of 89%, indicating it will be quite effective if used to detect CCF. It should be noted it does have a lower precision of 82%, although this is likely of less of interest in this case as we are move interested in our success in predicting actual fraud cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree Classifier\n",
    "DT = DecisionTreeClassifier(featuresCol = \"features\", predictionCol=\"prediction\", labelCol='is_fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit data to the model\n",
    "DT_clf = DT.fit(train_assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to predict class\n",
    "predictions_DT = DT_clf.transform(test_assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set:   0.9286300636973891\n",
      "Recall on test set:     0.9297568684526363\n",
      "Precision on test set:  0.9280231782874303\n",
      "ROC on test set:        0.9286270043444489\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy, recall, precision\n",
    "DT_accuracy = accuracy_evaluator.evaluate(predictions_DT)\n",
    "print(\"Accuracy on test set:  \", DT_accuracy)\n",
    "DT_recall = recall_evaluator.evaluate(predictions_DT)\n",
    "print(\"Recall on test set:    \", DT_recall)\n",
    "DT_precision = precision_evaluator.evaluate(predictions_DT)\n",
    "print(\"Precision on test set: \", DT_precision)\n",
    "ROC = ROC_evaluator.evaluate(predictions_DT)\n",
    "print(\"ROC on test set:       \", ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[342409  25869]\n",
      " [ 26557 339732]]\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix of results\n",
    "y_true = predictions_DT.select(['is_fraud']).collect()\n",
    "y_pred = predictions_DT.select(['prediction']).collect()\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93    368278\n",
      "           1       0.93      0.93      0.93    366289\n",
      "\n",
      "    accuracy                           0.93    734567\n",
      "   macro avg       0.93      0.93      0.93    734567\n",
      "weighted avg       0.93      0.93      0.93    734567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate pre-made classification report as a snaity check and to get weighted and f1-scores\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree classifier has achieved very good results with around 93% across the park in all metrics and overtakes LogisticRegression as our most successful classifier. It appears to be a good, well-balanced classifier on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Random Forest Classifier\n",
    "RF = RandomForestClassifier(featuresCol = \"features\", predictionCol=\"prediction\", labelCol='is_fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit data to the model\n",
    "RF_clf = RF.fit(train_assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use model to predict class\n",
    "predictions_RF = RF_clf.transform(test_assembled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set:   0.8510646408019963\n",
      "Recall on test set:     0.9625608915004426\n",
      "Precision on test set:  0.7875717888048345\n",
      "ROC on test set:        0.8507619207603909\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy, recall, precision\n",
    "RF_accuracy = accuracy_evaluator.evaluate(predictions_RF)\n",
    "print(\"Accuracy on test set:  \", RF_accuracy)\n",
    "RF_recall = recall_evaluator.evaluate(predictions_RF)\n",
    "print(\"Recall on test set:    \", RF_recall)\n",
    "RF_precision = precision_evaluator.evaluate(predictions_RF)\n",
    "print(\"Precision on test set: \", RF_precision)\n",
    "ROC = ROC_evaluator.evaluate(predictions_RF)\n",
    "print(\"ROC on test set:       \", ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[354490  13788]\n",
      " [ 95615 270674]]\n"
     ]
    }
   ],
   "source": [
    "# Create confusion matrix of results\n",
    "y_true = predictions_RF.select(['is_fraud']).collect()\n",
    "y_pred = predictions_RF.select(['prediction']).collect()\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.87    368278\n",
      "           1       0.95      0.74      0.83    366289\n",
      "\n",
      "    accuracy                           0.85    734567\n",
      "   macro avg       0.87      0.85      0.85    734567\n",
      "weighted avg       0.87      0.85      0.85    734567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate pre-made classification report as a snaity check and to get weighted and f1-scores\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomForest Classifier also performed well although with less consistent results that the Decision Tree classifier. It achieved a respectable accuracy of 85% while scoring the highest of all models in recall with 96%. \n",
    "\n",
    "This makes the RandomForest Classifier our best performing model specifically at detecting cases of CCF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><i>Naive Bayes classifier:</i> Accuracy: 0.711, Recall: 0.714\n",
    "<br><i>Logistic Regression classifier:</i> Accuracy: 0.849, Recall: 0.891\n",
    "<br><i>Decision Tree classifier:</i> Accuracy: 0.929, Recall: 0.930\n",
    "<br><i>Random Forest classifier:</i> Accuracy: 0.851, Recall: 0.963"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most successful model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the overall goal of what is trying to be achieved, there are two possible choices as best model. \n",
    "\n",
    "If the goal is overall accuracy, the <b>Decision Tree Classifier</b> performs very well across the board achieving good results (93%) in detecting both cases of CCF and non-CCF. \n",
    "\n",
    "If the goal is specifially CCF detection and false positives are acceptable, the <b>Random Forest Classifier</b> performs particularly well with a recall of 96% while still achieving good overall results with an accuracy of 85%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save most successful model for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Decision Tree Classifier as 'DT_clf'\n",
    "DT_clf.write().overwrite().save('hdfs://lena/user/blive001/DT_clf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Random Forest Classifier as 'RF_clf'\n",
    "RF_clf.write().overwrite().save('hdfs://lena/user/blive001/RF_clf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
